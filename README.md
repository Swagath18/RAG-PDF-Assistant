# RAG PDF Chatbot - 100% Local

This is a **Streamlit-based chatbot** that allows users to upload PDFs and ask questions about the content. It runs **entirely locally**, meaning no API costs, no internet requirements, and full privacy.

---
## Workflow
![Alt Text](RAG_PDF_Github.png)

## Features
- ğŸ“‚ Upload multiple PDFs
- ğŸ” Vector search using **FAISS**
- ğŸ§  Embeddings with **Hugging Face models**
- ğŸ¤– Uses **Ollama (Llama 2)** for local inference
- âš¡ No API keys required
- ğŸ”’ Runs 100% on your local machine

---

## ğŸ›  Installation
### **1ï¸âƒ£ Create a Virtual Environment** (Optional but recommended)
```bash
python -m venv pdf-chat-env
source pdf-chat-env/bin/activate  # On Windows: pdf-chat-env\Scripts\activate
```

### **2ï¸âƒ£ Install Dependencies**
#### **Using `pip`**
```bash
pip install -r requirements.txt
```

#### **Using `conda` (for CPU versions only)**
```bash
conda install -c conda-forge pytorch transformers sentence-transformers faiss-cpu
pip install -r requirements.txt
```

---

## ğŸ— Project Structure
```
ğŸ“‚ pdf-chatbot
â”œâ”€â”€ ğŸ“„ app.py               # Main Streamlit app
â”œâ”€â”€ ğŸ“‚ modules
â”‚   â”œâ”€â”€ process_pdf.py      # PDF processing (text extraction, chunking)
â”‚   â”œâ”€â”€ vector_store.py     # FAISS vector database management
â”‚   â”œâ”€â”€ llm_inference.py    # Running Ollama for answering queries
â”‚   â”œâ”€â”€ config.py           # Configurations (chunk size, model settings)
â”‚   â”œâ”€â”€ __init__.py         # Module initialization
â”œâ”€â”€ ğŸ“‚ faiss_index          # Saved FAISS index (generated after processing PDFs)
â”œâ”€â”€ ğŸ“„ requirements.txt      # Dependencies
â”œâ”€â”€ ğŸ“„ README.md            # This file
```

---

## â–¶ï¸ How to Run
```bash
streamlit run app.py
```
Then open **`http://localhost:8501`** in your browser.

---

## ğŸ“ Usage
1. Upload one or more PDF files from the **sidebar**.
2. Set the **chunk size** (default: `300`).
3. Click **"Process Documents"** to generate embeddings.
4. Enter your question in the text box.
5. Get an AI-powered answer based on the PDFs!

---

## ğŸ— Technologies Used
- **Streamlit** (Web UI)
- **PyPDF2** (PDF text extraction)
- **LangChain** (Text chunking, LLM inference)
- **FAISS** (Vector search)
- **Hugging Face Embeddings** (Text representations)
- **Ollama (Llama 2)** (Local LLM for answering queries)

---

## âš ï¸ Troubleshooting
- **No answer or incorrect response?**
  - Ensure PDFs contain selectable text (scanned images wonâ€™t work)
  - Increase chunk size if responses lack context
- **Performance issues?**
  - Reduce chunk size for faster processing
  - Use `tinyllama` instead of `llama2` for quicker inference

---

## Future Enhancements
- âœ… Add support for **PDFs with scanned text (OCR)**
- âœ… Implement **multi-document summarization**
- âœ… Improve LLM response formatting and citations

---

## ğŸ’¡ Credits & License
Developed by **Swagath Babu**. Free for personal and research use. 

